{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "2021-04-26 23:18:51,592 : INFO : loading FastText object from FastTextintro.model\n",
      "2021-04-26 23:18:51,659 : INFO : loading wv recursively from FastTextintro.model.wv.* with mmap=None\n",
      "2021-04-26 23:18:51,660 : INFO : loading vectors_ngrams from FastTextintro.model.wv.vectors_ngrams.npy with mmap=None\n",
      "2021-04-26 23:18:51,920 : INFO : setting ignored attribute buckets_word to None\n",
      "2021-04-26 23:18:51,922 : INFO : setting ignored attribute vectors to None\n",
      "2021-04-26 23:18:56,570 : INFO : setting ignored attribute cum_table to None\n",
      "2021-04-26 23:18:57,357 : INFO : FastText lifecycle event {'fname': 'FastTextintro.model', 'datetime': '2021-04-26T23:18:57.357849', 'gensim': '4.0.1', 'python': '3.6.13 (default, Feb 19 2021, 05:17:09) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Mar  9 20:06:37 2021\n",
    "\n",
    "@author: claud\n",
    "\"\"\"\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "model = FastText.load(\"FastTextintro.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['planets', 'sun']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#Gravity\n",
    "question =\"\"\"What makes the planets go around the sun?\"\"\"\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "is_verb = lambda pos: pos[:2] == 'VB'\n",
    "is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "\n",
    "# do the nlp stuff\n",
    "tokenized = nltk.word_tokenize(question)\n",
    "nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)  or is_adj(pos)] \n",
    "print(nouns)\n",
    "gravity = model.wv.most_similar(positive=nouns, topn=200)\n",
    "# print(gravity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'volatile', 'gas']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "question =\"\"\"What is the most volatile gas?\"\"\"\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "is_verb = lambda pos: pos[:2] == 'VB'\n",
    "is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "\n",
    "# do the nlp stuff\n",
    "tokenized = nltk.word_tokenize(question)\n",
    "nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos) or is_adj(pos) or is_verb(pos)] \n",
    "print(nouns)\n",
    "answers = model.wv.most_similar(positive=nouns, topn=200)\n",
    "# print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uses', 'diesel', 'fuel']\n"
     ]
    }
   ],
   "source": [
    "def filter_question(question)\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    is_verb = lambda pos: pos[:2] == 'VB'\n",
    "    is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "\n",
    "    # do the nlp stuff\n",
    "    tokenized = nltk.word_tokenize(question)\n",
    "    nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos) or is_adj(pos) or is_verb(pos)] \n",
    "    print(nouns)\n",
    "    answers = model.wv.most_similar(positive=nouns, topn=200)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['has', 'cpu', 'hard', 'drive', 'memory']\n",
      "['hardware', 'disk', 'disks', 'optimizer', 'toolset', 'toolbox', 'handhelds', 'mainframe', 'microprocessors', 'computers', 'interface', 'loader', 'microprocessor', 'supercomputers', 'desktops', 'multiprocessor', 'modem', 'input', 'microphones', 'socket', 'microcontroller', 'machines', 'firewall', 'optimize', 'stack', 'microcontrollers', 'trackless', 'machine', 'ethernet', 'supercomputer', 'sensors', 'smartphones', 'microphone', 'processor', 'handsets', 'toolbar', 'load', 'wire', 'chipset', 'desktop', 'microcomputer', 'filesystem', 'feedback', 'mainframes', 'algorithmic', 'computer', 'softdisk', 'optimization', 'preprocessor', 'solver', 'coprocessor', 'prowse', 'login', 'storage', 'tool', 'laptops', 'vmware', 'cach', 'configuration', 'motherboards', 'package', 'algorithm', 'threadgill', 'drawback', 'bits', 'amplifiers', 'tracking', 'widget', 'configure', 'calculators', 'console', 'firewire', 'fastener', 'drivetrain', 'slider', 'encryption', 'compatibility', 'tools', 'smartphone', 'computation', 'compressors', 'ide', 'turntables', 'virtualization', 'packet', 'module', 'freeware', 'timing', 'modulators', 'robustness', 'amplifier', 'accelerometer', 'microkernel', 'computability', 'simulators', 'reload', 'fingerprint', 'inverter', 'biofeedback', 'prow', 'lever', 'hash', 'reconfiguration', 'threads', 'chipsets', 'qubit', 'intels', 'software', 'loads', 'switchboard', 'wires', 'mindset', 'weatherboard', 'fingerboard', 'expendable', 'sequencing', 'workstation', 'dimple', 'kinect', 'automation', 'transistors', 'amplifies', 'functionals', 'fuse', 'soundsystem', 'modulator', 'motherboard', 'filter', 'buffer', 'customization', 'loaders', 'controller', 'client', 'netware', 'browsing', 'laptop', 'scalability', 'minicomputer', 'stools', 'layouts', 'switches', 'haystack', 'expendables', 'preset', 'install', 'disconnect', 'receptacle', 'needlework', 'stride', 'compactness', 'compress', 'multiplatform', 'timeframe', 'graphics', 'pad', 'layout', 'compression', 'antennal', 'microwave', 'portability', 'platform', 'slide', 'shortcuts', 'transistor', 'contactless', 'phones', 'downlink', 'maneuverability', 'replicates', 'interlock', 'mip', 'controllers', 'decode', 'multifunction', 'backlog', 'hardtop', 'emulation', 'gigabit', 'output', 'convertibles', 'connectors', 'automaton', 'bandwidth', 'gbit', 'processing', 'accelerometers', 'grid', 'openvms', 'appliance', 'modulate', 'tireless', 'synchronization', 'autodesk', 'plugins', 'scanner', 'offload', 'mode', 'oscillators', 'mbit', 'backpacking', 'optimizations', 'simplifies', 'freeform', 'microsd', 'qualcomm', 'application', 'hadoop', 'tracker', 'handling', 'muzzle']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def filter_question(question):\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    is_verb = lambda pos: pos[:2] == 'VB'\n",
    "    is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "\n",
    "    # do the nlp stuff\n",
    "    tokenized = nltk.word_tokenize(question)\n",
    "    nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos) or is_adj(pos) or is_verb(pos)] \n",
    "    print(nouns)\n",
    "    answers = model.wv.most_similar(positive=nouns, topn=500)\n",
    "    return answers\n",
    "\n",
    "def get_answers(word_type,doc_answers):\n",
    "    filtered_answers = []\n",
    "    \n",
    "    for answer in doc_answers:\n",
    "#         print(answer.text, answer.lemma_, answer.pos_, answer.tag_, answer.dep_,\n",
    "#                 answer.shape_, answer.is_alpha, answer.is_stop)\n",
    "        if (answer.tag_ == word_type or answer.tag_ == word_type+\"S\" or  answer.tag_ == word_type+\"P\"):\n",
    "            if(answer.dep_ == \"compound\" or answer.dep_ == \"dobj\" or answer.dep_ == \"npadvmod\"):\n",
    "                filtered_answers.append(answer.text)\n",
    "            \n",
    "         \n",
    "    return filtered_answers\n",
    "\n",
    "question = \"What has a cpu, hard drive and memory\"\n",
    "answers = filter_question(question)\n",
    "res_list = [x[0] for x in answers]\n",
    "str1 = ' '.join(res_list)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc_question = nlp(question)\n",
    "doc_answers = nlp(str1)\n",
    "\n",
    "for token in doc_question:\n",
    "    if (token.tag_ == \"WP\" or token.tag_ == \"WDT\" or token.tag_==\"WRB\" ):\n",
    "        filtered_a = get_answers(\"NN\",doc_answers)\n",
    "        print(filtered_a)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_a.index('gravitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
