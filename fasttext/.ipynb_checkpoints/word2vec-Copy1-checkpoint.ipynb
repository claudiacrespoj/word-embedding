{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-22 22:00:31,010 : INFO : loading Word2Vec object from word2vecintro.model\n",
      "2021-04-22 22:00:31,820 : INFO : loading wv recursively from word2vecintro.model.wv.* with mmap=None\n",
      "2021-04-22 22:00:31,821 : INFO : setting ignored attribute vectors_norm to None\n",
      "2021-04-22 22:00:31,822 : INFO : loading vocabulary recursively from word2vecintro.model.vocabulary.* with mmap=None\n",
      "2021-04-22 22:00:31,823 : INFO : loading trainables recursively from word2vecintro.model.trainables.* with mmap=None\n",
      "2021-04-22 22:00:31,823 : INFO : setting ignored attribute cum_table to None\n",
      "2021-04-22 22:00:31,824 : INFO : loaded word2vecintro.model\n",
      "2021-04-22 22:00:31,992 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mechanic', 0.6695517301559448), ('landing', 0.6566985845565796), ('ride', 0.6470464468002319), ('pilots', 0.6423074007034302), ('piloted', 0.6421835422515869), ('supercharger', 0.6370060443878174), ('brake', 0.6344720125198364), ('jet', 0.6340823769569397), ('flyer', 0.6290863156318665), ('airplane', 0.62720787525177)]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Mar  9 20:06:37 2021\n",
    "\n",
    "@author: claud\n",
    "\"\"\"\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "model = FastText.load(\"word2vecintro.model\")\n",
    "w1 = \"train\"\n",
    "a = model.wv.most_similar(positive=['pilot','drive'], topn=10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['makes', 'planets', 'go', 'sun']\n",
      "[('planet', 0.7136623859405518), ('moon', 0.6917630434036255), ('earth', 0.6828765869140625), ('orbiting', 0.671616792678833), ('jupiters', 0.6642177104949951), ('aphelion', 0.6559368371963501), ('heavens', 0.6515147089958191), ('orbits', 0.6496855020523071), ('jupiter', 0.6486647129058838), ('celestial', 0.6331124305725098)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#Gravity\n",
    "question =\"\"\"What makes the planets go around the sun?\"\"\"\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "is_verb = lambda pos: pos[:2] == 'VB'\n",
    "is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "\n",
    "# do the nlp stuff\n",
    "tokenized = nltk.word_tokenize(question)\n",
    "nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos) or is_verb(pos) or is_adj(pos)] \n",
    "print(nouns)\n",
    "gravity = model.wv.most_similar(positive=nouns, topn=10)\n",
    "print(gravity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'volatile', 'gas']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#Gravity\n",
    "question =\"\"\"What is the most volatile gas?\"\"\"\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "is_verb = lambda pos: pos[:2] == 'VB'\n",
    "is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "\n",
    "# do the nlp stuff\n",
    "tokenized = nltk.word_tokenize(question)\n",
    "nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos) or is_adj(pos) or is_verb(pos)] \n",
    "print(nouns)\n",
    "answers = model.wv.most_similar(positive=nouns, topn=200)\n",
    "# print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hydrocarbon', 'methane', 'solvent', 'vapour', 'liquids', 'gases', 'petroleum', 'methanol', 'propylene', 'fuels', 'hydrogen', 'crude', 'fractionation', 'feedstock', 'sulfur', 'dioxide', 'fuel', 'ethanol', 'ethane', 'extraction', 'acetylene', 'helium', 'butane', 'petrochemical', 'mixtures', 'glycol', 'fertilizer', 'solvents', 'organics', 'uranium', 'diethyl', 'energy', 'chemicals', 'butanol', 'iodine', 'distillation', 'adsorption', 'fertiliser', 'dinitrogen', 'substance', 'mineral', 'biomass', 'biogas', 'lpg', 'chlorine', 'particulates', 'phenols', 'lithium', 'vapors', 'monoxide', 'oil', 'waste', 'byproduct', 'turpentine', 'isopropyl', 'quenching', 'sodium', 'cellulosic', 'sweetener', 'isomerization', 'sulphate', 'crystalline', 'fumes', 'decompose', 'emulsions', 'separator', 'deuterium', 'fluorine', 'carbon', 'vacuum', 'biodiesel', 'reacts', 'oxidizer', 'refineries', 'dilute', 'petrochemicals', 'urea', 'caesium', 'emits']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def get_answers(word_type,doc_answers):\n",
    "    filtered_answers = []\n",
    "    \n",
    "    for answer in doc_answers:\n",
    "#         print(answer.text, answer.lemma_, answer.pos_, answer.tag_, answer.dep_,\n",
    "#                 answer.shape_, answer.is_alpha, answer.is_stop)\n",
    "        if (answer.tag_ == word_type or answer.tag_ == word_type+\"S\"):\n",
    "            if(answer.dep_ == \"compound\" or answer.dep_ == \"dobj\" or answer.dep_ == \"npadvmod\"):\n",
    "                filtered_answers.append(answer.text)\n",
    "            \n",
    "#             print(answer.text, answer.lemma_, answer.pos_, answer.tag_, answer.dep_,\n",
    "#                 answer.shape_, answer.is_alpha, answer.is_stop)\n",
    "            \n",
    "    return filtered_answers\n",
    "\n",
    "res_list = [x[0] for x in answers]\n",
    "str1 = ' '.join(res_list)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc_question = nlp(question)\n",
    "doc_answers = nlp(str1)\n",
    "\n",
    "for token in doc_question:\n",
    "#     print(token.tag_)\n",
    "    if (token.tag_ == \"WP\" or token.tag_ == \"WDT\" or token.tag_==\"WRB\" ):\n",
    "#         print(token.text)\n",
    "        #'wh-pronoun, personal'\"\"\n",
    "        filtered_a = get_answers(\"NN\",doc_answers)\n",
    "        print(filtered_a)\n",
    "            \n",
    "#         print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#                 token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun phrase as adverbial modifier'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"npadvmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:word2vec]",
   "language": "python",
   "name": "conda-env-word2vec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
