{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-27 00:49:14,956 : INFO : loading Word2Vec object from word2vecintro.model\n",
      "2021-04-27 00:49:15,684 : INFO : loading wv recursively from word2vecintro.model.wv.* with mmap=None\n",
      "2021-04-27 00:49:15,685 : INFO : setting ignored attribute vectors_norm to None\n",
      "2021-04-27 00:49:15,686 : INFO : loading vocabulary recursively from word2vecintro.model.vocabulary.* with mmap=None\n",
      "2021-04-27 00:49:15,687 : INFO : loading trainables recursively from word2vecintro.model.trainables.* with mmap=None\n",
      "2021-04-27 00:49:15,687 : INFO : setting ignored attribute cum_table to None\n",
      "2021-04-27 00:49:15,688 : INFO : loaded word2vecintro.model\n",
      "2021-04-27 00:49:15,851 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mechanic', 0.6695517301559448), ('landing', 0.6566985845565796), ('ride', 0.6470464468002319), ('pilots', 0.6423074007034302), ('piloted', 0.6421835422515869), ('supercharger', 0.6370060443878174), ('brake', 0.6344720125198364), ('jet', 0.6340823769569397), ('flyer', 0.6290863156318665), ('airplane', 0.62720787525177)]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Mar  9 20:06:37 2021\n",
    "\n",
    "@author: claud\n",
    "\"\"\"\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "model = Word2Vec.load(\"word2vecintro.model\")\n",
    "w1 = \"train\"\n",
    "a = model.wv.most_similar(positive=['pilot','drive'], topn=10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['makes', 'planets', 'go', 'sun']\n",
      "[('planet', 0.7136623859405518), ('moon', 0.6917630434036255), ('earth', 0.6828765869140625), ('orbiting', 0.671616792678833), ('jupiters', 0.6642177104949951), ('aphelion', 0.6559368371963501), ('heavens', 0.6515147089958191), ('orbits', 0.6496855020523071), ('jupiter', 0.6486647129058838), ('celestial', 0.6331124305725098)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#Gravity\n",
    "question =\"\"\"What makes the planets go around the sun?\"\"\"\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "is_verb = lambda pos: pos[:2] == 'VB'\n",
    "is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "\n",
    "# do the nlp stuff\n",
    "tokenized = nltk.word_tokenize(question)\n",
    "nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos) or is_verb(pos) or is_adj(pos)] \n",
    "print(nouns)\n",
    "gravity = model.wv.most_similar(positive=nouns, topn=10)\n",
    "print(gravity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'volatile', 'gas']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#Gravity\n",
    "question =\"\"\"What is the most volatile gas?\"\"\"\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "is_verb = lambda pos: pos[:2] == 'VB'\n",
    "is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "\n",
    "# do the nlp stuff\n",
    "tokenized = nltk.word_tokenize(question)\n",
    "nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos) or is_adj(pos) or is_verb(pos)] \n",
    "print(nouns)\n",
    "answers = model.wv.most_similar(positive=nouns, topn=200)\n",
    "# print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['has', 'cpu', 'hard', 'drive', 'memory']\n",
      "['sdram', 'disk', 'processor', 'hardware', 'bit', 'sram', 'gigabyte', 'bios', 'dram', 'cpus', 'coprocessor', 'multiprocessor', 'microprocessor', 'circuitry', 'computers', 'processors', 'hdd', 'microcontroller', 'ssd', 'fpgas', 'peripherals', 'controller', 'fpga', 'chip', 'hypervisor', 'firewire', 'intel', 'backplane', 'load', 'servo', 'tape', 'laptop', 'chipset', 'nvidia', 'nand', 'microcontrollers', 'intels', 'input', 'kib', 'multiuser', 'device', 'flash', 'controllers', 'ibm', 'cuda', 'sandbox', 'storage', 'chips', 'cores', 'emulator', 'pcs', 'amds', 'compatibility', 'devices', 'supercharger', 'macintosh', 'blaster', 'sequencer', 'computer', 'gpus', 'chipsets', 'microcomputers', 'touchscreen', 'console', 'adapters', 'timer', 'accumulator', 'router', 'connector', 'microchip', 'transistor', 'emulators', 'latency', 'outputs', 'emulates', 'user', 'tester', 'interconnect', 'functionality', 'machine', 'server', 'laptops', 'roms', 'desktop', 'ram', 'workload', 'mainframe', 'switches', 'bootstrap', 'mems', 'slots', 'wifi', 'sparc', 'itanium', 'simd', 'optimizer', 'ethernet', 'joystick', 'scalability', 'transformer', 'pentium', 'calculator', 'setups']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def filter_question(question):\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    is_verb = lambda pos: pos[:2] == 'VB'\n",
    "    is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "\n",
    "    # do the nlp stuff\n",
    "    tokenized = nltk.word_tokenize(question)\n",
    "    nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos) or is_adj(pos) or is_verb(pos)] \n",
    "    print(nouns)\n",
    "    answers = model.wv.most_similar(positive=nouns, topn=200)\n",
    "    return answers\n",
    "\n",
    "def get_answers(word_type,doc_answers):\n",
    "    filtered_answers = []\n",
    "    \n",
    "    for answer in doc_answers:\n",
    "#         print(answer.text, answer.lemma_, answer.pos_, answer.tag_, answer.dep_,\n",
    "#                 answer.shape_, answer.is_alpha, answer.is_stop)\n",
    "        if (answer.tag_ == word_type or answer.tag_ == word_type+\"S\" or  answer.tag_ == word_type+\"P\"):\n",
    "            if(answer.dep_ == \"compound\" or answer.dep_ == \"dobj\" or answer.dep_ == \"npadvmod\"):\n",
    "                filtered_answers.append(answer.text)\n",
    "            \n",
    "         \n",
    "    return filtered_answers\n",
    "\n",
    "question = \"What has a cpu, hard drive and memory\"\n",
    "answers = filter_question(question)\n",
    "res_list = [x[0] for x in answers]\n",
    "str1 = ' '.join(res_list)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc_question = nlp(question)\n",
    "doc_answers = nlp(str1)\n",
    "\n",
    "for token in doc_question:\n",
    "    if (token.tag_ == \"WP\" or token.tag_ == \"WDT\" or token.tag_==\"WRB\" ):\n",
    "        filtered_a = get_answers(\"NN\",doc_answers)\n",
    "        print(filtered_a)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_a.index('oxygen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:word2vec]",
   "language": "python",
   "name": "conda-env-word2vec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
